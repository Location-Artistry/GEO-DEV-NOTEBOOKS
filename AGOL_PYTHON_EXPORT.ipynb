{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AGOL-PYTHON-EXPORT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "l5KcKTRMumdG",
        "c2Ha3EWdla7Q",
        "fAjJ9kfABtZF"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM7wvDyx/ZLwaj9bmdE7OIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Location-Artistry/GEO-DEV-NOTEBOOKS/blob/main/AGOL_PYTHON_EXPORT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAzr6mSB6Zoq"
      },
      "source": [
        "#**Working Water Data Pandas AWQMS Export**\n",
        "Updated August 12th - Working with pandas dataframe exporting to excel   \n",
        "Working function to run download and CSV formatting in pandas   \n",
        "**8-14 Completed: Download & Export Functions, QuickMap Display**\n",
        "**8-25 delMultiple, updated Kzoo Dashboard Status**   \n",
        "**8-25 This Notebook has most current Python Functions!!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5KcKTRMumdG"
      },
      "source": [
        "# Install and Import Libraries\n",
        "**RUN FIRST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyTdckWPWdHm"
      },
      "source": [
        "!pip install xlsxwriter\n",
        "!pip install xlrd\n",
        "!pip install openpyxl\n",
        "!pip install arcgis\n",
        "#!pip install pdfkit\n",
        "#import pdfkit\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import datetime as dt\n",
        "import time as tm\n",
        "import math\n",
        "from arcgis.gis import GIS, Item\n",
        "from arcgis.env import active_gis\n",
        "from arcgis.features import FeatureLayerCollection\n",
        "from arcgis.mapping import WebMap\n",
        "from IPython.display import display\n",
        "import getpass\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "from openpyxl import load_workbook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwAlRhT2Po-2"
      },
      "source": [
        "userLogin()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQRNDUx6RmFl"
      },
      "source": [
        "import json \n",
        "import requests\n",
        "import arcgis.mapping\n",
        "jsonURL = 'https://services5.arcgis.com/UDWrEU6HdWNYIRIV/arcgis/rest/services/WATER_SAMPLING_2020_d4e27d13e2da43bfb8e300db323e349d/FeatureServer?f=json'\n",
        "# print(jsonURL)\n",
        "response = requests.get(jsonURL)\n",
        "resText = response.text\n",
        "data = json.loads(resText)\n",
        "#display(data)\n",
        "\n",
        "arcgis.mapping.export_map(data,'JPG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DvGbF4OWw68"
      },
      "source": [
        "#searchInfo = searchByKeywords(gis,'')\n",
        "for x in searchInfo[3]:\n",
        "  print(f'{x} - {searchInfo[3][x]}')\n",
        "#getUserContent(gis)\n",
        "#searchInfo[3].url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9vNJrKMjZ3c"
      },
      "source": [
        "# Python Functions from my ArcGIS Python Colab Notebook  \n",
        "**MUST RUN THIS CELL AFTER INSTALL AND IMPORT THEN - userLogin() -**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4Ffhx69jTSl"
      },
      "source": [
        "# Collection of all ArcGIS Python API Helper Functions\n",
        "# user login functions, ask if user would like additional logins\n",
        "def userLogin():\n",
        "    userID = input(f'ArcGIS Online USER ID: ')\n",
        "    passWord = getpass.getpass('PASSWORD: ')\n",
        "    try:\n",
        "        global gis\n",
        "        gis = GIS(\"https://www.arcgis.com\", userID, passWord)\n",
        "        print(f'SUCCESS - CONNECTED TO: {gis.users.me.username} ACCOUNT as <gis>')\n",
        "        print(gis)\n",
        "        addUsers = input(f'Additional User Login(YES/NO)? ')\n",
        "        if addUsers.upper() == 'YES':\n",
        "            additionalUserLogin()\n",
        "        else:\n",
        "            print(f'YOU MAY NOW PROCEED...')\n",
        "    except:\n",
        "        print(f'ERROR DID NOT CONNECT TO: {userID}')\n",
        "\n",
        "def additionalUserLogin():\n",
        "    userID = input(f'ArcGIS Online USER ID: ')\n",
        "    passWord = getpass.getpass('PASSWORD: ')\n",
        "    try:\n",
        "        global gis2\n",
        "        gis2 = GIS(\"https://www.arcgis.com\", userID, passWord)\n",
        "        print(f'SUCCESS - CONNECTED TO: {gis2.users.me.username} ACCOUNT as <gis2>')\n",
        "        print(gis2)\n",
        "    except:\n",
        "        print(f'ERROR DID NOT CONNECT TO: {userID}')\n",
        "\n",
        "# get list of all owner AGOL items, print list with title, id, type, and categories\n",
        "def getUserContent(gisInfo):\n",
        "    try:\n",
        "        my_content = gisInfo.content.search(query=\"owner:\" + gisInfo.users.me.username, item_type=\"\", max_items=200)\n",
        "        for x in my_content:\n",
        "            strMod = str(x.modified)\n",
        "            stampInt = int(strMod[0:10])\n",
        "            print(f'{x.title} - {x.id} - {x.type} - {x.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "    except:\n",
        "        print('ERROR could not get user content')\n",
        "\n",
        "# Clone item using id of item passed to function\n",
        "def cloneItem(gisInfo, gisInfo2, cloneID):    \n",
        "    try:\n",
        "        itemToClone = gisInfo.content.get(cloneID)\n",
        "        print('Cloning:' + itemToClone.title + ' - ' + itemToClone.id + ' -',itemToClone.type)\n",
        "        clonedItem = gisInfo2.content.clone_items(items=[itemToClone])\n",
        "        print(f'Cloned Item: {clonedItem[0]}')\n",
        "        #return clonedItem\n",
        "    except:\n",
        "        print('ERROR Could Not Clone')\n",
        "\n",
        "# updated searchByKeywords, returns LIST of items 8-14-2020\n",
        "def searchByKeywords(gisInfo, searchKeywords):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type='', max_items=50)\n",
        "        x = 0\n",
        "        for z in searchContent:\n",
        "          strMod = str(z.modified)\n",
        "          stampInt = int(strMod[0:10])\n",
        "          print(f'{x} - {z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "          x += 1\n",
        "        return searchContent\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "\n",
        "# find item by keywords and display visual card\n",
        "def searchByKeyViz(gisInfo, searchKeywords):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type='', max_items=50)\n",
        "        for z in searchContent:\n",
        "            print(f'title: {z.title} - itemID: {z.id} - type: {z.type}')\n",
        "            display(z)\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "        \n",
        "# return all keys and values for item when passed itemID string\n",
        "def getItemKeysValues(gisInfo, idString):\n",
        "    try:\n",
        "        getFeature = gisInfo.content.get(idString)\n",
        "        for key, value in getFeature.items():\n",
        "            print(key,': ', value)\n",
        "    except:\n",
        "        print('ERROR GET Keys/Values not Successful')\n",
        "        \n",
        "# takes itemID and gets and returns layerObject if exist, otherwise 'no layers found'\n",
        "def getLayers(gisInfo, idString):\n",
        "    getFeature = gisInfo.content.get(idString)\n",
        "    try:\n",
        "        featureLayers = getFeature.layers\n",
        "        z = 0 \n",
        "        for x in featureLayers:\n",
        "            print(f'Layer {z}: {x}')\n",
        "            z += 1\n",
        "    except:\n",
        "        print('no layers found')\n",
        "    return featureLayers\n",
        "\n",
        "# supply feature layer itemID, and the layer number to display table head \n",
        "def getLayerTable(gisInfo, idString, layerNum):\n",
        "    try:\n",
        "        layerOutput = getLayers(gisInfo, idString)\n",
        "        queryLayer = layerOutput[layerNum].query()\n",
        "        display(queryLayer.sdf.head())\n",
        "    except:\n",
        "        print('ERROR no Layers Found')\n",
        "        \n",
        "# delete item by itemID\n",
        "def deleteItem(gisInfo, idString):\n",
        "    itemToDelete = gisInfo.content.get(idString)\n",
        "    display(itemToDelete)\n",
        "    delQuest = input(f'Are you sure you want to delete: {itemToDelete.title}')\n",
        "    try:\n",
        "        if delQuest.upper() == 'YES':\n",
        "            print(f'DELETING: {itemToDelete.title}')\n",
        "            itemToDelete.delete()\n",
        "        else:\n",
        "            print(f'NOT DELETING: {itemToDelete.title}')\n",
        "    except:\n",
        "        print(f'ERROR failed to DELETE: {itemToDelete.title}')\n",
        "\n",
        "# delete multiple items by searchByKeywords() returned LIST 8-14-2020\n",
        "def delMultiple(gisInfo, itemList):\n",
        "  try:\n",
        "    print('List of Items to be Deleted: ')\n",
        "    for z in itemList:\n",
        "          strMod = str(z.modified)\n",
        "          stampInt = int(strMod[0:10])\n",
        "          print(f'{z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "    delQuest = input(f'SURE YOU WANT TO DELETE THESE?!?!?')\n",
        "    if delQuest.upper() == 'YES':\n",
        "      for z in itemList:\n",
        "          print(f'DELETING {z.title}')\n",
        "          itemToDelete = gisInfo.content.get(z.id)\n",
        "          itemToDelete.delete()\n",
        "      print('<FINISHED DELETION PROCESS>')\n",
        "    else:\n",
        "      print(f'NOT DELETING!')\n",
        "  except:\n",
        "      print(f'ERROR failed to DELETE: {itemToDelete.title}')\n",
        "\n",
        "# List all user Dashboards and Dashboard Webmmaps\n",
        "def ListAllDashWebmaps(gisInfo):\n",
        "  source_admin_inventory = get_user_items(gisInfo, gisInfo.users.me)\n",
        "  x = 0\n",
        "  try:\n",
        "    for dashboard in source_admin_inventory['Dashboard']:\n",
        "        print(x, dashboard)\n",
        "        dashWebmap = get_dash_wm(gisInfo, dashboard)\n",
        "        print(dashWebmap)\n",
        "        x += 1\n",
        "  except:\n",
        "    print(\"ERROR COULD NOT LIST DASHBOARDS\") \n",
        "\n",
        "# generic function update targetLayer Features based on Table Records\n",
        "def updateLayFeatFromTable(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib):\n",
        "  try:\n",
        "    getLayers = gisInfo.content.get(targetLayerID)\n",
        "    targetLayer = getLayers.layers\n",
        "    layerFeatures = targetLayer[0].query()\n",
        "    sourceTable = getLayers.tables\n",
        "    tableFeatures = sourceTable[0].query()\n",
        "    for tableFeature in tableFeatures:\n",
        "      tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "      for layerFeature in layerFeatures:\n",
        "        layerFeatureID = layerFeature.attributes[matchAttrib]\n",
        "        if tableFeatureID == layerFeatureID:\n",
        "          targetValue = tableFeature.attributes[sourceAttrib]\n",
        "          layerFeature.set_value(targetAttrib, targetValue)\n",
        "          print(f'feature: {layerFeatureID} from tableFeature: {tableFeatureID} set {targetAttrib} as: {targetValue}')\n",
        "    layerEdits = targetLayer[0].edit_features(updates=layerFeatures)\n",
        "    editCounter = 0\n",
        "    for edits in layerEdits['updateResults']:\n",
        "      editCounter+=1\n",
        "    print(f'updated {getLayers.title} with {editCounter} edits from {getLayers.tables[0]}')\n",
        "  except:\n",
        "    print(f'update features failed for {getLayers.title}')\n",
        "  \n",
        "# generic function update targetLayer Features based on Table Record, adds break list for parameter categories mapping/analysis\n",
        "# 8-14 Updated to screen for sampling records with blank values: 'None'\n",
        "def updateLayFeatFromTableBreaks(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib, breaksList):\n",
        "  try:\n",
        "    getLayers = gisInfo.content.get(targetLayerID)\n",
        "    targetLayer = getLayers.layers\n",
        "    layerFeatures = targetLayer[0].query()\n",
        "    sourceTable = getLayers.tables\n",
        "    tableFeatures = sourceTable[0].query()\n",
        "    for tableFeature in tableFeatures:\n",
        "      #tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "      print(tableFeature.attributes['WATER_TEMP'] is None)\n",
        "      if (tableFeature.attributes['WATER_TEMP'] is None) != True:\n",
        "        tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "        for layerFeature in layerFeatures:\n",
        "          layerFeatureID = layerFeature.attributes[matchAttrib]\n",
        "          if tableFeatureID == layerFeatureID:\n",
        "            targetValue = tableFeature.attributes[sourceAttrib]\n",
        "            x = 1\n",
        "            for breakVal in breaksList:\n",
        "              if targetValue > breakVal:\n",
        "                print('none')\n",
        "              else:\n",
        "                layerFeature.set_value(targetAttrib, x)\n",
        "                print(f'feature: {layerFeatureID} from tableFeature: {tableFeatureID} set {targetAttrib}: {targetValue} as: {x}')\n",
        "                break\n",
        "              x+=1\n",
        "    layerEdits = targetLayer[0].edit_features(updates=layerFeatures)\n",
        "    editCounter = 0\n",
        "    for edits in layerEdits['updateResults']:\n",
        "      editCounter+=1\n",
        "    # hide REST infor for updated layers and tables\n",
        "    # print(f'updated {getLayers.title} with {editCounter} edits from {getLayers.tables[0]}')\n",
        "    print(f'updated {getLayers.title} with {editCounter} edits')\n",
        "  except:\n",
        "    print(f'update features failed for {getLayers.title}')\n",
        "\n",
        "# download Feature Layer data from AGOL, unzip contents to folder with item.title name\n",
        "# Export Formats: Shapefile | CSV | File Geodatabase | Feature Collection | GeoJson | Scene Package | KML | Excel\n",
        "def downloadItem(gisInfo, idString):\n",
        "    try:\n",
        "        downloadData = gisInfo.content.get(idString)\n",
        "        dataPath = Path('/data')\n",
        "        print(f'Downloading: {downloadData.title} to {dataPath} directory')\n",
        "        if not dataPath.exists():\n",
        "          dataPath.mkdir()\n",
        "        # this portion for feature service\n",
        "        downloadExport = downloadData.export(title=downloadData.title, export_format=\"CSV\")\n",
        "        zipPath = downloadExport.download(save_path=dataPath)\n",
        "        # preparing to extract files to directory with item.title name\n",
        "        #zipPath = downloadData.download(save_path=dataPath)\n",
        "        extractPath = dataPath.joinpath(downloadData.title)\n",
        "        # extract files to /data directory\n",
        "        zipFiles = ZipFile(zipPath)\n",
        "        zipFiles.extractall(path=extractPath)\n",
        "        print(f'list of Files extracted to: {extractPath}')\n",
        "        print(list(file.name for file in extractPath.glob('*')))\n",
        "    except:\n",
        "        print('ERROR DOWNLOAD did not workings!')\n",
        "\n",
        "def searchItem(gisInfo, searchKeywords, itemType):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type=itemType, max_items=25)\n",
        "        if itemType == 'Feature Service':\n",
        "            x = 0\n",
        "            print(f'<Search Query for {searchKeywords}>')\n",
        "            for z in searchContent:\n",
        "                strMod = str(z.modified)\n",
        "                stampInt = int(strMod[0:10])\n",
        "                print(f'{x} - {z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "                x += 1\n",
        "            layInd = int(input(f'Index of selected Feature Layer: '))\n",
        "            addLayer = gisInfo.content.get(searchContent[layInd].id)\n",
        "            return addLayer\n",
        "        elif itemType == 'Web Map':\n",
        "            x = 0\n",
        "            print(f'<Search Query for {searchKeywords}>')\n",
        "            for z in searchContent:\n",
        "                strMod = str(z.modified)\n",
        "                stampInt = int(strMod[0:10])\n",
        "                print(f'{x} - {z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "                x += 1\n",
        "            layInd = int(input(f'Index of selected Feature Layer: ')) or 'NONE'\n",
        "            #print(searchContent[layInd])\n",
        "            mapReturn = searchContent[layInd]\n",
        "            return mapReturn\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "        \n",
        "def quickMap():\n",
        "  mapType = input(f'(YES) for QuickMap (NO) for Existing: ')\n",
        "  if mapType.upper() == 'NO':\n",
        "    mapSize = ['480px','720px','960px']\n",
        "    print(f'<You entered {mapType} please login below>')\n",
        "    userLogin() \n",
        "    mapKeywords = input(f'Name of WebMap to Search for: ') or ''\n",
        "    mapObj = searchItem(gis,mapKeywords,'Web Map')\n",
        "    map = gis.map(mapObj)\n",
        "    sizeIn = int(input(f'MAP SIZE (0)SMALL (1)MEDIUM (2)HUGE: '))\n",
        "    map.layout.height = mapSize[sizeIn]\n",
        "    display(map)\n",
        "  else:\n",
        "    print(f'<You entered {mapType} Opening QuickMap>')\n",
        "    mapList = ['topo','hybrid','streets','dark-gray','terrain']\n",
        "    mapDimen = ['2D','3D']\n",
        "    mapSize = ['480px','720px','960px']\n",
        "    mapLoc = input(f'Location (default=Michigan): ') or 'Michigan'\n",
        "    mapBaseNum = input(f'Basemap (default=topo (1=hybrid,2=streets,3=dark-gray,4=terrain): ') or 0\n",
        "    mapDimIn = input(f'ENTER (1) for 3D Map: ') or 0\n",
        "    atlasLayers = input(f'Layers from Living Atlas(Enter for None): ') or 'NONE'\n",
        "    gisNone = GIS()\n",
        "    map = gisNone.map(mapLoc)\n",
        "    map.basemap = mapList[int(mapBaseNum)]\n",
        "    if atlasLayers != 'NONE':\n",
        "        layerDisplay = searchItem(gisNone, atlasLayers,'Feature Service')\n",
        "        for layrs in layerDisplay.layers:\n",
        "            map.add_layer(layrs)\n",
        "    map.mode = mapDimen[int(mapDimIn)]\n",
        "    sizeIn = int(input(f'MAP SIZE (0)SMALL (1)MEDIUM (2)HUGE: '))\n",
        "    map.layout.height = mapSize[sizeIn]\n",
        "    display(map)\n",
        "\n",
        "# Delete all features from selected Feature Service, may need more debugging\n",
        "def delAllFeatures(gisInfo, idString):\n",
        "    delFeatures = gisInfo.content.get(idString)\n",
        "    display(delFeatures)\n",
        "    delQuest = input(f'Are you sure you want to delete all the feature in? {delFeatures.title}')\n",
        "    try:\n",
        "        if delQuest.upper() == 'YES':\n",
        "            print('in loop')\n",
        "            print(f'DELETING ALL FEATURES IN: {delFeatures.title}')\n",
        "            featDelRes = []\n",
        "            targetLayer = delFeatures.layers\n",
        "            layerFeatures = targetLayer[0].query()\n",
        "            for feature in layerFeatures:\n",
        "              #print(f'features: {feature.attributes}')\n",
        "              featDelRes.append(targetLayer[0].edit_features(deletes=str(feature.attributes['objectid'])))\n",
        "            return featDelRes\n",
        "        else:\n",
        "            print(f'NOT DELETING: {delFeatures.title}')\n",
        "    except:\n",
        "        print(f'ERROR failed to DELETE: {delFeatures.title}')\n",
        "\n",
        "# *******ESRI pre-made helper functions********\n",
        "def is_hosted(gisInfo, item):\n",
        "    return [keyword for keyword in item.typeKeywords if \"Hosted\" in keyword] \n",
        "\n",
        "# Prints all layers in a webmap, very handy\n",
        "def print_webmap_inventory(gisInfo, wm):\n",
        "    wm_obj = WebMap(wm)\n",
        "    print(f\"{wm_obj.item.title}\\n{'-'*100}\")\n",
        "    for wm_layer in wm_obj.layers:\n",
        "        try:\n",
        "            if is_hosted(Item(gisInfo, wm_layer['itemId'])):\n",
        "                print(f\"{' '*2}{wm_layer['title']:40}HOSTED{' ':5}\"\n",
        "                      f\"{wm_layer['layerType']:20}{dict(wm_layer)['itemId']}\")\n",
        "            else:\n",
        "                print(f\"{' '*2}{wm_layer['title']:40}other{' ':6}\"\n",
        "                      f\"{wm_layer['layerType']:20}{wm_layer.id}\") \n",
        "        except:\n",
        "            print(f\"{' '*2}{wm_layer['title']:40}other{' ':6}\"\n",
        "                  f\"{wm_layer['layerType']:20}{wm_layer.id}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "def get_webmap_list(wm):\n",
        "    wm_obj = WebMap(wm)\n",
        "    wmList = []\n",
        "    print(f\"{wm_obj.item.title}\\n{'-'*100}\")\n",
        "    for wm_layer in wm_obj.layers:\n",
        "        # print(wm_layer.itemId)\n",
        "        wmList.append(wm_layer.itemId)\n",
        "    return(wmList)\n",
        "    \n",
        "def displayWebmapLayers(gisInfo, idList):\n",
        "    for id in idList:\n",
        "        displayLayer = gisInfo.content.get(id)\n",
        "        display(displayLayer)\n",
        "\n",
        "def get_user_items(gisInfo, user):\n",
        "    user_inventory = {}\n",
        "    user_items = gisInfo.content.search(query=f\"* AND owner:{user.username}\", \n",
        "                                           max_items=500)\n",
        "    for item in user_items:\n",
        "        if item.type not in user_inventory:\n",
        "            user_inventory[item.type] = [i \n",
        "                                         for i in user_items \n",
        "                                         if i.type == item.type]\n",
        "    return user_inventory\n",
        "\n",
        "def print_user_inventory(inventory):\n",
        "    for itype, ilist in inventory.items():\n",
        "        try:\n",
        "            print(f\"{itype}\\n{'-'*50}\")\n",
        "            for i in ilist:\n",
        "                print(f\"{' ':3}{i.title:50}\")\n",
        "            print(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\t\\tOperation failed on: {i.title}\")\n",
        "            print(f\"\\t\\tException: {sys.exc_info()[1]}\")\n",
        "            continue\n",
        "            \n",
        "def get_dash_wm(gisInfo, dash):\n",
        "    return [gisInfo.content.get(widget['itemId']) \n",
        "            for widget in dash.get_data()['widgets'] \n",
        "            if widget['type'] == \"mapWidget\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Ha3EWdla7Q"
      },
      "source": [
        "# Python API Function List  \n",
        "**userLogin()** - **additionalUserLogin()** - **getUserContent** *(gisInfo)* - **cloneItem** *(gisInfo, gisInfo2, cloneID)*  \n",
        "**searchByKeywords** *(gisInfo, searchKeywords)* - **searchByKeyViz** *(gisInfo, searchKeywords)*  \n",
        "**getItemKeysValues** *(gisInfo, idString)* - **getLayers** *(gisInfo, idString)*\n",
        "**getLayerTable** *(gisInfo, idString, layerNum)* - **deleteItem** *(gisInfo, idString)*  \n",
        "**ListAllDashWebmaps** *(gisInfo)* - **updateLayFeatFromTable** *(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib)*  \n",
        "**updateLayFeatFromTableBreaks** *(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib, breaksList)*  \n",
        "**downloadItem** *(gisInfo, idString)* - **searchItem** *(gisInfo, searchKeywords, itemType)* - **quickMap()**   \n",
        "**delAllFeatures** *(gisInfo, itemID)* - **delMultiple** *(gisInfo, itemList)*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ESRI pre-made helper functions  \n",
        "**is_hosted** *(gisInfo, item)* - **print_webmap_inventory** *(gisInfo, wm)* - **get_webmap_list** *(wm)*  \n",
        "**displayWebmapLayers** *(gisInfo, idList)* - **get_user_items** *(gisInfo, user)*  \n",
        "**print_user_inventory** *(inventory)* - **get_dash_wm** *(gisInfo, dash)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nybZ5ek1_Dvz"
      },
      "source": [
        "# Work in Progress Cell(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjJ9kfABtZF"
      },
      "source": [
        "# Water Quality Dashboard Display Update Functions\n",
        "Updated KZOO Turb Status 7-23-2020 3:05 pm   \n",
        "Updated NHBP DO Status 7-23-2020 3:08 pm\n",
        "Upated NHBP DO Status 8-12-2020    \n",
        "Updated KZOO Turb Status 8-15-2020 - Refactored Update Layer function, check for 'None'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuEsYMwlB24T"
      },
      "source": [
        "# generic function update targetLayer Features based on Table Record, adds break list for parameter categories mapping/analysis\n",
        "# 8-14 Updated to screen for sampling records with blank values: 'None'\n",
        "def updateLayFeatFromTableBreaks(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib, breaksList):\n",
        "  try:\n",
        "    getLayers = gisInfo.content.get(targetLayerID)\n",
        "    targetLayer = getLayers.layers\n",
        "    layerFeatures = targetLayer[0].query()\n",
        "    sourceTable = getLayers.tables\n",
        "    tableFeatures = sourceTable[0].query()\n",
        "    for tableFeature in tableFeatures:\n",
        "      #tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "      print(tableFeature.attributes['WATER_TEMP'] is None)\n",
        "      if (tableFeature.attributes['WATER_TEMP'] is None) != True:\n",
        "        tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "        for layerFeature in layerFeatures:\n",
        "          layerFeatureID = layerFeature.attributes[matchAttrib]\n",
        "          if tableFeatureID == layerFeatureID:\n",
        "            targetValue = tableFeature.attributes[sourceAttrib]\n",
        "            x = 1\n",
        "            for breakVal in breaksList:\n",
        "              if targetValue > breakVal:\n",
        "                print('none')\n",
        "              else:\n",
        "                layerFeature.set_value(targetAttrib, x)\n",
        "                print(f'feature: {layerFeatureID} from tableFeature: {tableFeatureID} set {targetAttrib}: {targetValue} as: {x}')\n",
        "                break\n",
        "              x+=1\n",
        "    layerEdits = targetLayer[0].edit_features(updates=layerFeatures)\n",
        "    editCounter = 0\n",
        "    for edits in layerEdits['updateResults']:\n",
        "      editCounter+=1\n",
        "    # hide REST infor for updated layers and tables\n",
        "    # print(f'updated {getLayers.title} with {editCounter} edits from {getLayers.tables[0]}')\n",
        "    print(f'updated {getLayers.title} with {editCounter} edits')\n",
        "  except:\n",
        "    print(f'update features failed for {getLayers.title}')\n",
        "\n",
        "#userLogin()\n",
        "kzooLayerNHBP = 'dff379381a6b4b73a1d80b9fd42784a8'\n",
        "kzooLayerLA = '6b62d8b710e64b8abc79015fd7231b87'\n",
        "waterSampNHBP = '680016d676e746f98743f51d28abac60'\n",
        "match = 'SITE_ID'\n",
        "turbTarget = 'TURB_STATUS_'\n",
        "turbSource = 'TURB_NTU'\n",
        "turbRefList = [3.93,10,40,1000]\n",
        "DOtarget = 'DO_STATUS_'\n",
        "DOsource = 'DO_mgl'\n",
        "DOrefList = [5,6,7,100]\n",
        "# calc Turbidity Status from most recent sample\n",
        "#updateLayFeatFromTableBreaks(gis, kzooLayerNHBP, match, turbTarget, turbSource, turbRefList)\n",
        "# calc DO Status from most recent sample\n",
        "updateLayFeatFromTableBreaks(gis, waterSampNHBP, match, DOtarget, DOsource, DOrefList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpDtkVnf26JB"
      },
      "source": [
        "# **Working function to download and process WATER DATA**\n",
        "\n",
        "1.   (COMP) Download and extract WATER_SAMPLING_2020 (itemID: '680016d676e746f98743f51d28abac60')  \n",
        "2.   (COMP) Read Water Data Sample Table as Pandas Dataframe  \n",
        "3. (COMP)Drop uneeded columns/attributes  \n",
        "4. (NEXT STEP) Format correctly for AWQMS upload\n",
        "5. Write as XLS for export to AWQMS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFkqD5m5U0Nj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gqKECjl5jyM"
      },
      "source": [
        "# downloadReturn and exportAGOLdata work together with specified itemID to \n",
        "# package Export from AGOL into CSV, download and extract files, pass file\n",
        "# path back to export func which creates pandas dataframe, \n",
        "# ALL WORKING 9-9 -> Finishing Refactoring...\n",
        "# 9-10 -> AQWMS issues, fixed dates and times columns, more robust\n",
        "def exportWaterData():\n",
        "  \n",
        "  def downloadReturn(gisInfo, idString):\n",
        "    try:\n",
        "        downloadData = gisInfo.content.get(idString)\n",
        "        dataPath = Path('/data')\n",
        "        print(f'Downloading: {downloadData.title} to {dataPath} directory')\n",
        "        if not dataPath.exists():\n",
        "          dataPath.mkdir()\n",
        "        # this portion for feature service\n",
        "        downloadExport = downloadData.export(title=downloadData.title, export_format=\"CSV\")\n",
        "        zipPath = downloadExport.download(save_path=dataPath)\n",
        "        # preparing to extract files to directory with item.title name\n",
        "        extractPath = dataPath.joinpath(downloadData.title)\n",
        "        # extract files to /data directory\n",
        "        zipFiles = ZipFile(zipPath)\n",
        "        zipFiles.extractall(path=extractPath)\n",
        "        # delete CSV created by export\n",
        "        print(f'Deleting CSV export generated by Download: {downloadExport.title} ID: {downloadExport.id}')\n",
        "        itemToDelete = gisInfo.content.get(downloadExport.id)\n",
        "        itemToDelete.delete()\n",
        "        print(f'list of Files extracted to: {extractPath}')\n",
        "        print(list(file.name for file in extractPath.glob('*')))\n",
        "        returnArray = []\n",
        "        for x in extractPath.glob('*'):\n",
        "          returnArray.append(x)\n",
        "        return returnArray\n",
        "    except:\n",
        "        print('ERROR DOWNLOAD did not workings!')\n",
        "\n",
        "  def exportDataFrame(df, exportName):\n",
        "    try:\n",
        "      writer = pd.ExcelWriter(exportName, engine='xlsxwriter')\n",
        "      df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "      writer.save()\n",
        "      print(f'dataframe successfully exported as: {exportName}')\n",
        "      return df\n",
        "    except:\n",
        "      print('exportDataFrame function failed')\n",
        "\n",
        "  # function to download and process data as specified above\n",
        "  def exportAGOLdata(gis, itemID, exportName='exportXLS.xlsx'):\n",
        "    try:\n",
        "      DLdata = downloadReturn(gis, itemID)\n",
        "      if str(DLdata[0])[-5] == '1':\n",
        "        fullPath = DLdata[0]\n",
        "      else: \n",
        "        fullPath = DLdata[1]\n",
        "      print(fullPath)\n",
        "      df = pd.read_csv(fullPath)\n",
        "      display(df)\n",
        "      dfED = exportDataFrame(df,exportName)\n",
        "      print('<Dataframe Header created from AGOL item Export>')\n",
        "      return dfED\n",
        "    except:\n",
        "      print(f'ERROR with {itemID} EXPORT')\n",
        "\n",
        "  #Done 9-8-2020 - Just need to organize!\n",
        "  # 9-9 -> Cleanup up and organized into functions, dfV2 local/global resolved\n",
        "  def formatXLS(dfEX):\n",
        "    # Lookup dict for site number linked to ID, define destination dataFrame\n",
        "    siteList = {'DKC-ST-30':1,'DKC-ST-50':2,'FDP-SD-10':3,'ICD-ST-20':4,'ICD-ST-40':5,'ICD-ST-60':6,'KAR-ST-100':7,'KAR-ST-200':8,'NOT-ST-110':9,'NOT-ST-120':10,'NOT-ST-130':11,'NOT-ST-30':12,'NOT-ST-50':13,'NOT-ST-60':14,'NOT-ST-70':15,'NOT-ST-80':16,'NOT-ST-90':17,'PGC-ST-30':18,'PNC-ST-20':19,'PNC-ST-30':20,'PNC-ST-40':21,'PNC-ST-50':22,'PNC-ST-60':23,'PNC-ST-70':24,'QDP-LA-10':25,'RDP-SD-10':26,'SCD-ST-20':27,'SCD-ST-40':28,'SCD-ST-50':29,'SDP-LA-10':30,'UNT-ST-10':31,'UNT-ST-20':32,'ICD-ST-70':33,'HVC-ST-20':34,'NOT-ST-140':35,'NOT-ST-40':36,'DKC-ST-20':37,'DKC-ST-25':38,'NOT-ST-115':39,'PNC-ST-45':40,'ICD-ST-65':41,'SPC-ST-90':42,'SJR-ST-300':43}\n",
        "    dfV2 = pd.DataFrame()\n",
        "    # Define functions to transform/convert values for attributes\n",
        "    def actType(QCval):\n",
        "        if QCval == 'Field Measurement':\n",
        "          return 'Field Msr/Obs'\n",
        "        else:\n",
        "          return 'Quality Control Field Replicate Msr/Obs'\n",
        "    def FtoC(Ftemp):\n",
        "      Ctemp = (int(Ftemp) - 32) * (5/9)\n",
        "      return round(Ctemp, 2)\n",
        "    def getDate(dateTime):\n",
        "      splitDate = dateTime.split('/')\n",
        "      if int(splitDate[0]) < 10:\n",
        "        monthName = '0' + splitDate[0]\n",
        "      else:\n",
        "        monthName = splitDate[0]\n",
        "      if int(splitDate[1]) < 10:\n",
        "        dayName = '0' + splitDate[1]\n",
        "      else:\n",
        "        dayName = splitDate[1]\n",
        "      splitDate = splitDate[2].split(' ')\n",
        "      sampYear = splitDate[0]\n",
        "      dateString = (f'{sampYear}{monthName}{dayName}')\n",
        "      return dateString\n",
        "    def isQC(qcInfo):\n",
        "      returnVal = ''\n",
        "      if qcInfo == 'Quality Control Sample Field Replicate':\n",
        "        returnVal = ':QC'\n",
        "      return returnVal\n",
        "    def dateInfo(DATE_TIME):\n",
        "      splitDate = DATE_TIME.split(' ')\n",
        "      return splitDate\n",
        "    def time24(DATE_TIME):\n",
        "      splitTime = DATE_TIME.split(' ')\n",
        "      dayTime = splitTime[1]\n",
        "      dayTime = dayTime.split(':')\n",
        "      hourTime = int(dayTime[0])\n",
        "      minTime = int(dayTime[1])\n",
        "      if minTime < 10:\n",
        "        minTime = (f'0{str(minTime)}')\n",
        "      if splitTime[2].upper() == 'PM':\n",
        "        hourTime = int(dayTime[0]) + 12\n",
        "      hourTime = hourTime - 5\n",
        "      if hourTime < 10:\n",
        "        hourTime = (f'0{str(hourTime)}')\n",
        "      return hourTime,minTime\n",
        "    def equipType(SAMP_EQUIP):\n",
        "      if SAMP_EQUIP.upper() == 'YSI PRODSS':\n",
        "        equipType = 'Probe/Sensor'\n",
        "      else:\n",
        "        equipType = 'Water Bottle'\n",
        "      return equipType\n",
        "\n",
        "    def convertValues():\n",
        "      dfEX['SAMP_EQUIP'] = dfEX.apply(lambda row: equipType(row.SAMP_EQUIP), axis=1)\n",
        "      dfEX['SITE #'] = dfEX.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "      dfV2['SITE #'] = dfEX.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "      numString = 'SITE #'\n",
        "      dfV2['FIELD Activity ID'] = dfEX.apply(lambda row: row.SITE_ID + ':' + str(row['SITE #']) + ':'+ getDate(row.DATE_TIME)+':'+ str(time24(row.DATE_TIME)[0]) + str(time24(row.DATE_TIME)[1]) + isQC(row.QC), axis = 1)\n",
        "      dfV2['Activity Type'] = dfEX.apply(lambda x: actType(x['QC']), axis = 1)\n",
        "      dfV2['DATE'] = dfEX.apply(lambda row: dateInfo(row.DATE_TIME)[0], axis = 1)\n",
        "      dfV2['TIME'] = dfEX.apply(lambda row: str(time24(row.DATE_TIME)[0])+':'+str(time24(row.DATE_TIME)[1]), axis = 1)\n",
        "      dfV2['TEMP C'] = dfEX.apply(lambda x: FtoC(x['WATER_TEMP']), axis = 1)\n",
        "      dfV2['SPCOND'] = dfEX['SPEC_COND_uS_cm']*.001\n",
        "      dfV2['DO%'] = ''\n",
        "      dfV2['pH'] = round(dfEX['pH'],1)\n",
        "    def AssignCol(dfV2):\n",
        "      dfCol = ['Monitoring Location','Sample Collection Equipment Name','TEMP F','TURB','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']\n",
        "      srcCol = ['SITE_ID','SAMP_EQUIP','WATER_TEMP','TURB_NTU','DO_mgl','TOT_NITRO_','TOT_PHOS_','Ecoli_100ml_','NOTES']\n",
        "      x = 0\n",
        "      for col in dfCol:\n",
        "        dfV2[col] = dfEX[srcCol[x]]\n",
        "        x+=1\n",
        "      dfV2 = dfV2[['FIELD Activity ID','Monitoring Location','SITE #','Activity Type','Sample Collection Equipment Name','DATE','TIME','TEMP C','TEMP F','SPCOND','pH','TURB','DO%','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']]\n",
        "      return dfV2\n",
        "    #function main body, convert values, name and organize DataFrame columns  \n",
        "    convertValues()\n",
        "    dfV3 = AssignCol(dfV2)\n",
        "    return dfV3\n",
        "  #--main function body flow--\n",
        "\n",
        "  loginQuest = input(f'Do you need to Login to ArcGIS Online(YES) or (NO)? ')\n",
        "  if loginQuest.upper() == 'YES':\n",
        "    userLogin()\n",
        "  searchQuest = input(f'ArcGIS Online Feature Service Search: ')\n",
        "  searchReturn = searchByKeywords(gis, searchQuest)\n",
        "  indexNumber = input(f'What is the index of the file search target? ')\n",
        "  fileName = input(f'File Name for the XLSX export? ')\n",
        "  exportName = (f'{fileName}.xlsx')\n",
        "  dfEX = exportAGOLdata(gis, searchReturn[int(indexNumber)].id, exportName)\n",
        "  dfExport = formatXLS(dfEX)\n",
        "  exportDataFrame(dfExport, exportName)\n",
        "  #display(dfExport)\n",
        "  return dfExport\n",
        "\n",
        "dataExport = exportWaterData()\n",
        "dataExport.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5b_0I93lhMT"
      },
      "source": [
        "dfEZ = exportAGOLdata(gis, item[3].id, 'exportXLS.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvImkNkCocF2"
      },
      "source": [
        "dataExport = exportWaterData()\n",
        "dataExport.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2suknEztvF6q"
      },
      "source": [
        "##working edited function to get 2019 data   \n",
        "only one layer download, so function breaks when expecting water stations and water table data   \n",
        "something adjust, check to see how many layers are part of the Feature Service Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ypfwOCsmPZ6"
      },
      "source": [
        "  datTest = dataExport.dropna(subset=['WATER_TEMP'])\n",
        "  datTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGKoI2OAN4jZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "0d6e6951-6b68-4c39-d246-decb9f4f0fe5"
      },
      "source": [
        "# this is the working section 9-21-2020\n",
        "# Finally Looking good!!!\n",
        "\n",
        "def downloadReturn(gisInfo, idString):\n",
        "    try:\n",
        "        downloadData = gisInfo.content.get(idString)\n",
        "        dataPath = Path('/data')\n",
        "        print(f'Downloading: {downloadData.title} to {dataPath} directory')\n",
        "        if not dataPath.exists():\n",
        "          dataPath.mkdir()\n",
        "        # this portion for feature service\n",
        "        downloadExport = downloadData.export(title=downloadData.title, export_format=\"CSV\")\n",
        "        zipPath = downloadExport.download(save_path=dataPath)\n",
        "        # preparing to extract files to directory with item.title name\n",
        "        extractPath = dataPath.joinpath(downloadData.title)\n",
        "        # extract files to /data directory\n",
        "        zipFiles = ZipFile(zipPath)\n",
        "        zipFiles.extractall(path=extractPath)\n",
        "        # delete CSV created by export\n",
        "        print(f'Deleting CSV export generated by Download: {downloadExport.title} ID: {downloadExport.id}')\n",
        "        itemToDelete = gisInfo.content.get(downloadExport.id)\n",
        "        itemToDelete.delete()\n",
        "        print(f'list of Files extracted to: {extractPath}')\n",
        "        print(list(file.name for file in extractPath.glob('*')))\n",
        "        returnArray = []\n",
        "        for x in extractPath.glob('*'):\n",
        "          returnArray.append(x)\n",
        "        return returnArray\n",
        "    except:\n",
        "        print('ERROR DOWNLOAD did not workings!')\n",
        "\n",
        "def exportAGOLdata(gis, itemID, exportName='exportXLS.xlsx'):\n",
        "      DLdata = downloadReturn(gis, itemID)\n",
        "      #if str(DLdata[0])[-5] == '1':\n",
        "      #  fullPath = DLdata[0]\n",
        "      #else: \n",
        "      #  fullPath = DLdata[1]\n",
        "      # small change with 2019 data - only one layer in download\n",
        "      fullPath = DLdata[0]\n",
        "      print(fullPath)\n",
        "      df = pd.read_csv(fullPath)\n",
        "      #display(df)\n",
        "      #dfED = exportDataFrame(df,exportName)\n",
        "      print('<Dataframe Header created from AGOL item Export>')\n",
        "      return df\n",
        "      print(f'ERROR with {itemID} EXPORT')\n",
        "\n",
        "# refactoring One more time 9-14.....\n",
        "def formatXLS(dfSOURCE):\n",
        "    # Lookup dict for site number linked to ID, define destination dataFrame\n",
        "    siteList = {'DKC-ST-30':1,'DKC-ST-50':2,'FDP-SD-10':3,'ICD-ST-20':4,'ICD-ST-40':5,'ICD-ST-60':6,'KAR-ST-100':7,'KAR-ST-200':8,'NOT-ST-110':9,'NOT-ST-120':10,'NOT-ST-130':11,'NOT-ST-30':12,'NOT-ST-50':13,'NOT-ST-60':14,'NOT-ST-70':15,'NOT-ST-80':16,'NOT-ST-90':17,'PGC-ST-30':18,'PNC-ST-20':19,'PNC-ST-30':20,'PNC-ST-40':21,'PNC-ST-50':22,'PNC-ST-60':23,'PNC-ST-70':24,'QDP-LA-10':25,'RDP-SD-10':26,'SCD-ST-20':27,'SCD-ST-40':28,'SCD-ST-50':29,'SDP-LA-10':30,'UNT-ST-10':31,'UNT-ST-20':32,'ICD-ST-70':33,'HVC-ST-20':34,'NOT-ST-140':35,'NOT-ST-40':36,'DKC-ST-20':37,'DKC-ST-25':38,'NOT-ST-115':39,'PNC-ST-45':40,'ICD-ST-65':41,'SPC-ST-90':42,'SJR-ST-300':43}\n",
        "  \n",
        "    # Define functions to transform/convert values for attributes\n",
        "    def actType(QCval):\n",
        "        if QCval == 'Field Measurement':\n",
        "          return 'Field Msr/Obs'\n",
        "        else:\n",
        "          return 'Quality Control Field Replicate Msr/Obs'\n",
        "    def FtoC(Ftemp):\n",
        "      # working here...\n",
        "      if type(Ftemp) == 'int':\n",
        "        Ctemp = (int(Ftemp) - 32) * (5/9)\n",
        "        CtempRound = round(Ctemp, 2)\n",
        "        return CtempRound\n",
        "      else:\n",
        "        return 'NULL'\n",
        "    def getDate(dateTime):\n",
        "      splitDate = dateTime.split('/')\n",
        "      if int(splitDate[0]) < 10:\n",
        "        monthName = '0' + splitDate[0]\n",
        "      else:\n",
        "        monthName = splitDate[0]\n",
        "      if int(splitDate[1]) < 10:\n",
        "        dayName = '0' + splitDate[1]\n",
        "      else:\n",
        "        dayName = splitDate[1]\n",
        "      splitDate = splitDate[2].split(' ')\n",
        "      sampYear = splitDate[0]\n",
        "      dateString = (f'{sampYear}{monthName}{dayName}')\n",
        "      return dateString\n",
        "    def isQC(qcInfo):\n",
        "      returnVal = ''\n",
        "      if qcInfo == 'Quality Control Sample Field Replicate':\n",
        "        returnVal = ':QC'\n",
        "      return returnVal\n",
        "    def dateInfo(DATE_TIME):\n",
        "      splitDate = DATE_TIME.split(' ')\n",
        "      return splitDate\n",
        "    def time24(DATE_TIME):\n",
        "      splitTime = DATE_TIME.split(' ')\n",
        "      dayTime = splitTime[1]\n",
        "      dayTime = dayTime.split(':')\n",
        "      hourTime = int(dayTime[0])\n",
        "      minTime = int(dayTime[1])\n",
        "      if minTime < 10:\n",
        "        minTime = (f'0{str(minTime)}')\n",
        "      if splitTime[2].upper() == 'PM':\n",
        "        hourTime = int(dayTime[0]) + 12\n",
        "      hourTime = hourTime - 5\n",
        "      if hourTime < 10:\n",
        "        hourTime = (f'0{str(hourTime)}')\n",
        "      return hourTime,minTime\n",
        "    def equipType(SAMP_EQUIP):\n",
        "      if SAMP_EQUIP.upper() == 'YSI PRODSS':\n",
        "        equipType = 'Probe/Sensor'\n",
        "      else:\n",
        "        equipType = 'Water Bottle'\n",
        "      return equipType\n",
        "\n",
        "    def convertValuesNew(dfEY):\n",
        "      dfV2 = pd.DataFrame()\n",
        "      dfV2['SITE #'] = dfEY.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "      numString = 'SITE #'\n",
        "      dfV2['FIELD Activity ID'] = dfEY.apply(lambda row: row.SITE_ID + ':' + str(row['SITE #']) + ':'+ getDate(row.DATE_TIME)+':'+ str(time24(row.DATE_TIME)[0]) + str(time24(row.DATE_TIME)[1]) + isQC(row.QC), axis = 1)\n",
        "      dfV2['Activity Type'] = dfEY.apply(lambda x: actType(x['QC']), axis = 1)\n",
        "      dfV2['DATE'] = dfEY.apply(lambda row: dateInfo(row.DATE_TIME)[0], axis = 1)\n",
        "      dfV2['TIME'] = dfEY.apply(lambda row: str(time24(row.DATE_TIME)[0])+':'+str(time24(row.DATE_TIME)[1]), axis = 1)\n",
        "      dfV2['TEMP C'] = dfEY.apply(lambda x: FtoC(x['WATER_TEMP']), axis = 1)\n",
        "      dfV2['SPCOND'] = dfEY['SPEC_COND_uS_cm']*.001\n",
        "      dfV2['DO%'] = ''\n",
        "      dfV2['pH'] = round(dfEY['pH'],1)\n",
        "      return dfV2\n",
        "\n",
        "#    def AssignCol(dfV3, dfEX):\n",
        "#      dfCol = ['Monitoring Location','Sample Collection Equipment Name','TEMP F','TURB','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']\n",
        "#      srcCol = ['SITE_ID','SAMP_EQUIP','WATER_TEMP','TURB_NTU','DO_mgl','TOT_NITRO_','TOT_PHOS_','Ecoli_100ml_','NOTES']\n",
        "#      x = 0\n",
        "#      for col in dfCol:\n",
        "#        dfV3[col] = dfEX[srcCol[x]]\n",
        "#        x+=1\n",
        "#      dfV3 = dfV3[['FIELD Activity ID','Monitoring Location','SITE #','Activity Type','Sample Collection Equipment Name','DATE','TIME','TEMP C','TEMP F','SPCOND','pH','TURB','DO%','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']]\n",
        "#      return dfV3\n",
        "    dfNewSource = dfSOURCE.dropna(subset=['WATER_TEMP'])\n",
        "    \n",
        "    #dfSOURCE['SAMP_EQUIP'] = dfSOURCE.apply(lambda row: equipType(row.SAMP_EQUIP), axis=1)\n",
        "    #dfSOURCE['SITE #'] = dfSOURCE.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "    dfNewSource['SAMP_EQUIP'] = dfNewSource.apply(lambda row: equipType(row.SAMP_EQUIP), axis=1)\n",
        "    dfNewSource['SITE #'] = dfNewSource.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "\n",
        "    dfNewMod = convertValuesNew(dfNewSource)\n",
        "\n",
        "    dfCol = ['Monitoring Location','Sample Collection Equipment Name','TEMP F','TURB','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']\n",
        "    srcCol = ['SITE_ID','SAMP_EQUIP','WATER_TEMP','TURB_NTU','DO_mgl','TOT_NITRO','TOT_PHOS','Ecoli_100ml','NOTES']\n",
        "    x = 0\n",
        "    #display(dfSOURCE.head())\n",
        "    for col in dfCol:\n",
        "      dfNewMod[col] = dfNewSource[srcCol[x]]\n",
        "      x+=1\n",
        "    \n",
        "    dfFINAL = dfNewMod[['FIELD Activity ID','Monitoring Location','SITE #','Activity Type','Sample Collection Equipment Name','DATE','TIME','TEMP C','TEMP F','SPCOND','pH','TURB','DO%','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']]\n",
        "    \n",
        "    #dfEZ = dfEX.dropna(subset=['WATER_TEMP'])\n",
        "\n",
        "    #dfSourceConv = convertValuesSource(dfSOURCE)\n",
        "    #dfNewMod = convertValuesNew(dfSOURCE)\n",
        "    #dfFINAL = AssignCol(dfNewMod, dfSOURCE)\n",
        "    #return dfNewMod\n",
        "    writer = pd.ExcelWriter('NHBP-2019-DATA.xlsx', engine='xlsxwriter')\n",
        "    dfFINAL.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "    writer.save()\n",
        "    print(f'dataframe successfully exported as: NHBP-2019-DATA.xlsx')\n",
        "    \n",
        "    return dfFINAL\n",
        "\n",
        "\n",
        "dfExport = exportAGOLdata(gis, searchReturn[0].id, exportName='exportXLS.xlsx')\n",
        "#dfExport.head()\n",
        "dfFormat = formatXLS(dfExport)\n",
        "#dfFormat.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: WATER_DATA_2019_CLEANED to /data directory\n",
            "Deleting CSV export generated by Download: WATER_DATA_2019_CLEANED ID: 97f2fc191e81450c8d357172c0683197\n",
            "list of Files extracted to: /data/WATER_DATA_2019_CLEANED\n",
            "['WATER_DATA_2019_CLEANED_0.csv']\n",
            "/data/WATER_DATA_2019_CLEANED/WATER_DATA_2019_CLEANED_0.csv\n",
            "<Dataframe Header created from AGOL item Export>\n",
            "dataframe successfully exported as: NHBP-2019-DATA.xlsx\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwlaHn4ZbtBL"
      },
      "source": [
        "## Done and downloaded 9-21-2020 ##\n",
        "Working 9-21 on 2019 data export   \n",
        "Not sure where I was last working, may need to review the entire workflow   \n",
        "May take several of the features out of the functio to simplify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LW57Ru7enR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "9dfc7950-03ea-4f5e-f999-e466760c1e05"
      },
      "source": [
        "dfFormat.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FIELD Activity ID</th>\n",
              "      <td>PNC-ST-40:21:20190725:1455</td>\n",
              "      <td>UNT-ST-10:31:20190725:1510:QC</td>\n",
              "      <td>UNT-ST-10:31:20190725:1509</td>\n",
              "      <td>PNC-ST-50:22:20190725:1526</td>\n",
              "      <td>NOT-ST-120:10:20190815:1319</td>\n",
              "      <td>NOT-ST-50:13:20190815:1401</td>\n",
              "      <td>NOT-ST-110:9:20190815:1352</td>\n",
              "      <td>NOT-ST-70:15:20190815:1402</td>\n",
              "      <td>PNC-ST-30:20:20190815:1426</td>\n",
              "      <td>PNC-ST-40:21:20190827:1219</td>\n",
              "      <td>PNC-ST-40:21:20190827:1220:QC</td>\n",
              "      <td>PNC-ST-45:40:20190827:1238</td>\n",
              "      <td>PNC-ST-50:22:20190827:1249</td>\n",
              "      <td>PNC-ST-60:23:20190827:1312</td>\n",
              "      <td>NOT-ST-110:9:20190827:1500</td>\n",
              "      <td>NOT-ST-80:16:20190828:1350</td>\n",
              "      <td>NOT-ST-90:17:20190828:1411</td>\n",
              "      <td>NOT-ST-110:9:20190828:1441</td>\n",
              "      <td>SCD-ST-40:28:20190710:1312</td>\n",
              "      <td>PNC-ST-60:23:20190710:1325</td>\n",
              "      <td>PNC-ST-60:23:20190710:1326:QC</td>\n",
              "      <td>PNC-ST-50:22:20190710:1336</td>\n",
              "      <td>ICD-ST-40:5:20190710:1347</td>\n",
              "      <td>PNC-ST-60:23:20190719:0940</td>\n",
              "      <td>PNC-ST-60:23:20190719:0941:QC</td>\n",
              "      <td>PNC-ST-50:22:20190720:0-355</td>\n",
              "      <td>NOT-ST-110:9:20190720:0-245</td>\n",
              "      <td>ICD-ST-40:5:20190930:1058</td>\n",
              "      <td>PNC-ST-50:22:20190930:1108</td>\n",
              "      <td>PNC-ST-60:23:20190930:1118</td>\n",
              "      <td>SCD-ST-40:28:20190930:1126</td>\n",
              "      <td>SCD-ST-40:28:20190930:1130:QC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Monitoring Location</th>\n",
              "      <td>PNC-ST-40</td>\n",
              "      <td>UNT-ST-10</td>\n",
              "      <td>UNT-ST-10</td>\n",
              "      <td>PNC-ST-50</td>\n",
              "      <td>NOT-ST-120</td>\n",
              "      <td>NOT-ST-50</td>\n",
              "      <td>NOT-ST-110</td>\n",
              "      <td>NOT-ST-70</td>\n",
              "      <td>PNC-ST-30</td>\n",
              "      <td>PNC-ST-40</td>\n",
              "      <td>PNC-ST-40</td>\n",
              "      <td>PNC-ST-45</td>\n",
              "      <td>PNC-ST-50</td>\n",
              "      <td>PNC-ST-60</td>\n",
              "      <td>NOT-ST-110</td>\n",
              "      <td>NOT-ST-80</td>\n",
              "      <td>NOT-ST-90</td>\n",
              "      <td>NOT-ST-110</td>\n",
              "      <td>SCD-ST-40</td>\n",
              "      <td>PNC-ST-60</td>\n",
              "      <td>PNC-ST-60</td>\n",
              "      <td>PNC-ST-50</td>\n",
              "      <td>ICD-ST-40</td>\n",
              "      <td>PNC-ST-60</td>\n",
              "      <td>PNC-ST-60</td>\n",
              "      <td>PNC-ST-50</td>\n",
              "      <td>NOT-ST-110</td>\n",
              "      <td>ICD-ST-40</td>\n",
              "      <td>PNC-ST-50</td>\n",
              "      <td>PNC-ST-60</td>\n",
              "      <td>SCD-ST-40</td>\n",
              "      <td>SCD-ST-40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SITE #</th>\n",
              "      <td>21</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>40</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity Type</th>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Quality Control Field Replicate Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Quality Control Field Replicate Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Quality Control Field Replicate Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Quality Control Field Replicate Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Field Msr/Obs</td>\n",
              "      <td>Quality Control Field Replicate Msr/Obs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sample Collection Equipment Name</th>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "      <td>Probe/Sensor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <td>7/25/2019</td>\n",
              "      <td>7/25/2019</td>\n",
              "      <td>7/25/2019</td>\n",
              "      <td>7/25/2019</td>\n",
              "      <td>8/15/2019</td>\n",
              "      <td>8/15/2019</td>\n",
              "      <td>8/15/2019</td>\n",
              "      <td>8/15/2019</td>\n",
              "      <td>8/15/2019</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>8/28/2019</td>\n",
              "      <td>8/28/2019</td>\n",
              "      <td>8/28/2019</td>\n",
              "      <td>7/10/2019</td>\n",
              "      <td>7/10/2019</td>\n",
              "      <td>7/10/2019</td>\n",
              "      <td>7/10/2019</td>\n",
              "      <td>7/10/2019</td>\n",
              "      <td>7/19/2019</td>\n",
              "      <td>7/19/2019</td>\n",
              "      <td>7/20/2019</td>\n",
              "      <td>7/20/2019</td>\n",
              "      <td>9/30/2019</td>\n",
              "      <td>9/30/2019</td>\n",
              "      <td>9/30/2019</td>\n",
              "      <td>9/30/2019</td>\n",
              "      <td>9/30/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TIME</th>\n",
              "      <td>14:55</td>\n",
              "      <td>15:10</td>\n",
              "      <td>15:09</td>\n",
              "      <td>15:26</td>\n",
              "      <td>13:19</td>\n",
              "      <td>14:01</td>\n",
              "      <td>13:52</td>\n",
              "      <td>14:02</td>\n",
              "      <td>14:26</td>\n",
              "      <td>12:19</td>\n",
              "      <td>12:20</td>\n",
              "      <td>12:38</td>\n",
              "      <td>12:49</td>\n",
              "      <td>13:12</td>\n",
              "      <td>15:00</td>\n",
              "      <td>13:50</td>\n",
              "      <td>14:11</td>\n",
              "      <td>14:41</td>\n",
              "      <td>13:12</td>\n",
              "      <td>13:25</td>\n",
              "      <td>13:26</td>\n",
              "      <td>13:36</td>\n",
              "      <td>13:47</td>\n",
              "      <td>09:40</td>\n",
              "      <td>09:41</td>\n",
              "      <td>0-3:55</td>\n",
              "      <td>0-2:45</td>\n",
              "      <td>10:58</td>\n",
              "      <td>11:08</td>\n",
              "      <td>11:18</td>\n",
              "      <td>11:26</td>\n",
              "      <td>11:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TEMP C</th>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TEMP F</th>\n",
              "      <td>70</td>\n",
              "      <td>76.6</td>\n",
              "      <td>76.6</td>\n",
              "      <td>71.1</td>\n",
              "      <td>70.7</td>\n",
              "      <td>65.9</td>\n",
              "      <td>69.6</td>\n",
              "      <td>68.8</td>\n",
              "      <td>69.6</td>\n",
              "      <td>65.9</td>\n",
              "      <td>65.8</td>\n",
              "      <td>66</td>\n",
              "      <td>66.5</td>\n",
              "      <td>66.5</td>\n",
              "      <td>67.5</td>\n",
              "      <td>66.5</td>\n",
              "      <td>66.6</td>\n",
              "      <td>66.8</td>\n",
              "      <td>67.5</td>\n",
              "      <td>74.6</td>\n",
              "      <td>76.1</td>\n",
              "      <td>74</td>\n",
              "      <td>70.3</td>\n",
              "      <td>76.8</td>\n",
              "      <td>76.8</td>\n",
              "      <td>76.5</td>\n",
              "      <td>72.7</td>\n",
              "      <td>62.2</td>\n",
              "      <td>61.2</td>\n",
              "      <td>61.7</td>\n",
              "      <td>62.1</td>\n",
              "      <td>62.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SPCOND</th>\n",
              "      <td>0.4665</td>\n",
              "      <td>0.4825</td>\n",
              "      <td>0.4829</td>\n",
              "      <td>0.4622</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.527</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.557</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.549</td>\n",
              "      <td>0.4032</td>\n",
              "      <td>0.4373</td>\n",
              "      <td>0.4034</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.4688</td>\n",
              "      <td>0.4675</td>\n",
              "      <td>0.4684</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.3463</td>\n",
              "      <td>0.4085</td>\n",
              "      <td>0.4112</td>\n",
              "      <td>0.3659</td>\n",
              "      <td>0.3659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pH</th>\n",
              "      <td>7.2</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.7</td>\n",
              "      <td>8.2</td>\n",
              "      <td>7.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>7.7</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.9</td>\n",
              "      <td>8</td>\n",
              "      <td>7.9</td>\n",
              "      <td>8.2</td>\n",
              "      <td>7.6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>8</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.1</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.7</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TURB</th>\n",
              "      <td>0</td>\n",
              "      <td>3.58</td>\n",
              "      <td>8.48</td>\n",
              "      <td>0</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.26</td>\n",
              "      <td>1.83</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.69</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.15</td>\n",
              "      <td>6.32</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>4.24</td>\n",
              "      <td>1.18</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.86</td>\n",
              "      <td>4.3</td>\n",
              "      <td>27.34</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1.39</td>\n",
              "      <td>48.76</td>\n",
              "      <td>50.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DO%</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DO mg/L</th>\n",
              "      <td>3.4</td>\n",
              "      <td>10.62</td>\n",
              "      <td>10.62</td>\n",
              "      <td>3.29</td>\n",
              "      <td>5.14</td>\n",
              "      <td>8.92</td>\n",
              "      <td>5.82</td>\n",
              "      <td>8.4</td>\n",
              "      <td>5.38</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.74</td>\n",
              "      <td>1.47</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2.9</td>\n",
              "      <td>6.84</td>\n",
              "      <td>8.04</td>\n",
              "      <td>7.75</td>\n",
              "      <td>7.21</td>\n",
              "      <td>8.2</td>\n",
              "      <td>2.87</td>\n",
              "      <td>2.51</td>\n",
              "      <td>2.6</td>\n",
              "      <td>7.02</td>\n",
              "      <td>1.27</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.87</td>\n",
              "      <td>6.49</td>\n",
              "      <td>7.6</td>\n",
              "      <td>2.85</td>\n",
              "      <td>2.95</td>\n",
              "      <td>8.03</td>\n",
              "      <td>8.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOT. N mg/L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOT. P mg/L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E. coli col/100 ml</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOTES</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Downstream side</td>\n",
              "      <td>Upstream side</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tract 22 Dock</td>\n",
              "      <td>Upstream of Athens</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Light film on water surface, very low DO</td>\n",
              "      <td>QC field replicate</td>\n",
              "      <td>Rice pond, heavy lily pad growth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Good rice up and downstream</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Platform still under water</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Very low DO reading</td>\n",
              "      <td>QC sample low DO</td>\n",
              "      <td>Less than 1 mgL of DO</td>\n",
              "      <td>Much higher DO than Pine Creek</td>\n",
              "      <td>Creek running high</td>\n",
              "      <td>Creek level up to platform</td>\n",
              "      <td>Heavy rain over weekend</td>\n",
              "      <td>Creek higher from weekend storms</td>\n",
              "      <td>QC taken right, DS side, samp takne left DS side</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          0   ...                                                36\n",
              "FIELD Activity ID                 PNC-ST-40:21:20190725:1455  ...                     SCD-ST-40:28:20190930:1130:QC\n",
              "Monitoring Location                                PNC-ST-40  ...                                         SCD-ST-40\n",
              "SITE #                                                    21  ...                                                28\n",
              "Activity Type                                  Field Msr/Obs  ...           Quality Control Field Replicate Msr/Obs\n",
              "Sample Collection Equipment Name                Probe/Sensor  ...                                      Probe/Sensor\n",
              "DATE                                               7/25/2019  ...                                         9/30/2019\n",
              "TIME                                                   14:55  ...                                             11:30\n",
              "TEMP C                                                  NULL  ...                                              NULL\n",
              "TEMP F                                                    70  ...                                              62.1\n",
              "SPCOND                                                0.4665  ...                                            0.3659\n",
              "pH                                                       7.2  ...                                               7.6\n",
              "TURB                                                       0  ...                                             50.65\n",
              "DO%                                                           ...                                                  \n",
              "DO mg/L                                                  3.4  ...                                              8.02\n",
              "TOT. N mg/L                                              NaN  ...                                               NaN\n",
              "TOT. P mg/L                                              NaN  ...                                               NaN\n",
              "E. coli col/100 ml                                       NaN  ...                                               NaN\n",
              "NOTES                                                    NaN  ...  QC taken right, DS side, samp takne left DS side\n",
              "\n",
              "[18 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NmVc7OjS5A_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "cb05864d-ed46-48c7-9b34-776b2e05556c"
      },
      "source": [
        "userLogin()\n",
        "searchReturn = searchByKeywords(gis, 'water data cleaned 2019')\n",
        "searchReturn[0].id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ArcGIS Online USER ID: ekerney_nhbptribe\n",
            "PASSWORD: \n",
            "SUCCESS - CONNECTED TO: ekerney_nhbptribe ACCOUNT as <gis>\n",
            "GIS @ https://nhbptribe.maps.arcgis.com version:8.2\n",
            "Additional User Login(YES/NO)? no\n",
            "YOU MAY NOW PROCEED...\n",
            "0 - WATER_DATA_2019_CLEANED - 00a27de719a8420c82a6d2985a8ff735 - Feature Service - ['/Categories/ENVIRONMENTAL DATA/WATER QUALITY'] - 2020-09-13 12:55:55\n",
            "1 - WATER_DATA_2019_CLEANED - 7410847228994c89885b60a0ede9c91c - CSV - ['/Categories/ENVIRONMENTAL DATA/WATER QUALITY'] - 2020-09-13 12:55:43\n",
            "2 - WATER_DATA_2019_CLEANED - 2937e8617ba648bca631af9a8978ce3e - CSV Collection - [] - 2020-09-21 19:12:06\n",
            "3 - WATER_DATA_2019_CLEANED - 929abf1f25e14edca449f5f526bffbe5 - CSV Collection - [] - 2020-09-21 17:22:01\n",
            "4 - WATER_DATA_2019_CLEANED - 95dea90331e94ac1b79850820d20b089 - CSV Collection - [] - 2020-09-21 19:29:14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'00a27de719a8420c82a6d2985a8ff735'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ls4y-dtGY2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98ea0c8a-7b97-49ab-eebc-82ecbada38c6"
      },
      "source": [
        "testString = 'yes its stringy'\n",
        "testInt = 42\n",
        "\n",
        "type(testString)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9-SZtyXk58b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3f6bd537-589f-4659-95fe-f7f2cb83d78e"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-608453bd-dd32-4de1-91f6-6a5f1b51287b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-608453bd-dd32-4de1-91f6-6a5f1b51287b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving WATER_DATA_2019_CLEANED.csv to WATER_DATA_2019_CLEANED.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7h-6nRHUDXo"
      },
      "source": [
        "dataPath = '/data/WATER_DATA_2019_CLEANED/WATER_DATA_2019_CLEANED_0.csv'\n",
        "df = pd.read_csv(dataPath)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsnN8bgMvsqh"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEYLErmBVNNx"
      },
      "source": [
        "delList = searchByKeywords(gis,'CSV-collection')\n",
        "delMultiple(gis,delList)\n",
        "#delList[17]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}